{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a69209cb",
   "metadata": {},
   "source": [
    "# Streaming Input Dataset\n",
    "\n",
    "We already covered the basics of an iterable dataset ([Python-02-Python](Pytorch-02-Python.ipynb)) and pytorch's `DataLoader` ([Python-05-Pytorch.ipynb](Python-05-Pytorch.ipynb)). In this notebook, we introduce a few datasets that will be used during the hands-on sessions, and practic looping over the dataset using `DataLoader`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ae291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "SEED=123\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dadfc02",
   "metadata": {},
   "source": [
    "## MNIST dataset\n",
    "\n",
    "MNIST is widely used for an introductory machine learning (ML) courses/lectures. Most, if not all, ML libraries provide an easy way (API) to access MNIST and many publicly available dataset. This is true in `pytorch` as well. MNIST dataset in `Dataset` instance is available from `torchvision`. \n",
    "\n",
    "### Creating MNIST Dataset\n",
    "A `torchvision` is a supporting module that has many image-related APIs including an interface (and management) of MNIST dataset. Let's see how we can construct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f11698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "# Data file download directory\n",
    "LOCAL_DATA_DIR = './mnist-data'\n",
    "# Use prepared data handler from pytorch (torchvision)\n",
    "dataset = datasets.MNIST(LOCAL_DATA_DIR, train=True, download=True,\n",
    "                         transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc1934a",
   "metadata": {},
   "source": [
    "Here, MNIST is also a type `Dataset` (how? through class inheritance). All torch `Dataset` instance have tow useful and common functions: the length representations and data element access via index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c11fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( len(dataset)  )\n",
    "print( type(dataset[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50321f8b",
   "metadata": {},
   "source": [
    "That being said, how each data element is presented depends on a particular `Dataset` implementation. In case of MNIST, it is a tuple of length 2: **data** and **label**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8392ec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTRY=0\n",
    "data, label = dataset[ENTRY]\n",
    "print('Type of data  :', type(data),  'shape', data.shape)\n",
    "print('Type of label :', type(label), 'value', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd6724b",
   "metadata": {},
   "source": [
    "MNIST is an image of a hand-written digit in 28x28 pixels, gray scale. Note that the data `shape` is `[1,28,28]`. This follows the convention in Pytorch for image data represented as $(Cannel,Height,Width)$, or in short $(C,H,W)$. Let's visualize using `matplotlib.pyplot.imshow`. This function can take $(H,W)$ of a gray scale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4924425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Draw data\n",
    "data = data.reshape(data.shape[1:])\n",
    "plt.imshow(data,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5c371b",
   "metadata": {},
   "source": [
    "Let us define a function that can list images and labels in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fae2e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset(dataset,num_image_per_class=10):\n",
    "    import numpy as np\n",
    "    num_class = 0\n",
    "    classes = []\n",
    "    if hasattr(dataset,'classes'):\n",
    "        classes=dataset.classes\n",
    "        num_class=len(classes)\n",
    "    else: #brute force\n",
    "        for data,label in dataset:\n",
    "            if label in classes: continue\n",
    "            classes.append(label)\n",
    "        num_class=len(classes)\n",
    "    \n",
    "    shape = dataset[0][0].shape\n",
    "    big_image = np.zeros(shape=[3,shape[1]*num_class,shape[2]*num_image_per_class],dtype=np.float32)\n",
    "    \n",
    "    finish_count_per_class=[0]*num_class\n",
    "    for data,label in dataset:\n",
    "        if finish_count_per_class[label] >= num_image_per_class: continue\n",
    "        img_ctr = finish_count_per_class[label]\n",
    "        big_image[:,shape[1]*label:shape[1]*(label+1),shape[2]*img_ctr:shape[2]*(img_ctr+1)]=data\n",
    "        finish_count_per_class[label] += 1\n",
    "        if np.sum(finish_count_per_class) == num_class*num_image_per_class: break\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig,ax=plt.subplots(figsize=(8,8),facecolor='w')\n",
    "    ax.tick_params(axis='both',which='both',bottom=False,top=False,left=False,right=False,labelleft=False,labelbottom=False)\n",
    "    plt.imshow(np.transpose(big_image,(1,2,0)))\n",
    "    for c in range(len(classes)):\n",
    "        plt.text(big_image.shape[1]+shape[1]*0.5,shape[2]*(c+0.6),str(classes[c]),fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9704996",
   "metadata": {},
   "source": [
    "Visualize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c50ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dae054e",
   "metadata": {},
   "source": [
    "### Creating DataLoader\n",
    "\n",
    "Since the MNIST dataset is an iteratable one, we can create pytorch DataLoader!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5d9897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "loader = torch.utils.data.DataLoader(dataset,\n",
    "                                     batch_size=20,\n",
    "                                     shuffle=True,\n",
    "                                     num_workers=1,\n",
    "                                     pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d7ef6d",
   "metadata": {},
   "source": [
    "**Review**: the first argument is you dataset, and it can be anything but requires two attributes: [`__len__`](https://docs.python.org/3/reference/datamodel.html#object.__len__) and [`__getitem__`](https://docs.python.org/3/reference/datamodel.html#object.__getitem__). In case you wonder, these attributes allow you to call `len(dataset)` and access dataset elements  by `dataset[X]` where `X` is an index integer.\n",
    "\n",
    "#### Details (ignore if wished): other constructor arguments\n",
    "The other constructor arguments used above are:\n",
    "* `batch_size` ... the same of the subset data to be provided at once\n",
    "* `shuffle` ... whether or not to randomize the choice of subset dataset (False will provide dataset\n",
    "* `num_workers` ... number of parallel data-reader processes to be run (for making data read faster using `multiprocessing` module)\n",
    "* `pin_memory` ... speed up data transfer to GPU by avoiding a necessity to copy data from pageable memory to page-locked (pinned) memory. Read [here](https://devblogs.nvidia.com/how-optimize-data-transfers-cuda-cc/) for more details. If you are not sure about the details, set to `True` when using GPU. \n",
    "\n",
    "### Data streaming with `DataLoader`\n",
    "So let's play with it! First of all, it has the concept of \"length\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd881ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('length of DataLoader:',len(loader))\n",
    "print('By the way, batch size * length =', 20 * len(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d3a754",
   "metadata": {},
   "source": [
    "We know the data total statistics is 60,000 which coincides with the length of `DataLoader` instance and the batch size where the latter is the unit of batch data. **Yep, as you guessed**, `DataLoader` is iterable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226f97a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an iterator for playin in this notebook\n",
    "from itertools import cycle\n",
    "iter = cycle(loader)\n",
    "\n",
    "for i in range(10):\n",
    "    batch = next(iter)    \n",
    "    print('Iteration',i)\n",
    "    print(batch[1]) # accessing the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9388bc",
   "metadata": {},
   "source": [
    "... and this is how `data` looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f1a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of an image batch data',batch[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fdfa60",
   "metadata": {},
   "source": [
    "... which is quite naturally 20 of 28x28 image\n",
    "\n",
    "\n",
    "## CIFAR10 \n",
    "\n",
    "`CIFAR10` is yet another public dataset of 32x32 pixels RGB photographs. It contains 10 classes like MNIST but it is much more complicated than a gray scale, hand-written digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bdebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "# Data file download directory\n",
    "LOCAL_DATA_DIR = './cifar10-data'\n",
    "# Create the dataset\n",
    "dataset = datasets.CIFAR10(LOCAL_DATA_DIR, train=True, download=True,\n",
    "                           transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "plot_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5db3eac",
   "metadata": {},
   "source": [
    "Nothing new in terms of how-to, but let's also create a `DataLoader` with `CIFAR10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ddd24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset,batch_size=8,shuffle=True,num_workers=1,pin_memory=True)\n",
    "\n",
    "batch = next(cycle(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b970a5bc",
   "metadata": {},
   "source": [
    "Let's take a look at the `batch` data. Recall the shape of this image $(C,H,W)$ where `matplotlib.pyplot.imshow` takes the format $(H,W,C)$ just like how an ordinary photograph is presented. We use `torch.permute` function to swap the axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b022b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "photos,labels=batch\n",
    "for idx in range(len(photos)):\n",
    "    photo = photos[idx].permute(1,2,0)\n",
    "    label = labels[idx]\n",
    "    print(dataset.classes[label])\n",
    "    plt.imshow(photo)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   14,
   19,
   25,
   33,
   40,
   43,
   46,
   49,
   54,
   57,
   65,
   68,
   99,
   102,
   104,
   109,
   116,
   129,
   132,
   135,
   144,
   147,
   149,
   157,
   166,
   169,
   173,
   176
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}