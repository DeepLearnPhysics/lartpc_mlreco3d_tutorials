{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "designed-benjamin",
   "metadata": {},
   "source": [
    "# Streaming Input Dataset\n",
    "\n",
    "We already covered the basics of an iterable dataset ([Python basics](./Pytorch-02-Python.md)) and pytorch's `DataLoader` ([pytorch introduction](Python-05-Pytorch.md)). In this notebook, we introduce a few datasets that will be used during the hands-on sessions, and practic looping over the dataset using `DataLoader`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "built-enemy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe8b2476de0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "SEED=123\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-footage",
   "metadata": {},
   "source": [
    "## MNIST dataset\n",
    "\n",
    "MNIST is widely used for an introductory machine learning (ML) courses/lectures. Most, if not all, ML libraries provide an easy way (API) to access MNIST and many publicly available dataset. This is true in `pytorch` as well. MNIST dataset in `Dataset` instance is available from `torchvision`. \n",
    "\n",
    "### Creating MNIST Dataset\n",
    "A `torchvision` is a supporting module that has many image-related APIs including an interface (and management) of MNIST dataset. Let's see how we can construct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prepared-trail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist-data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00791d69f6634b9081cc9e703844763a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "# Data file download directory\n",
    "LOCAL_DATA_DIR = './mnist-data'\n",
    "os.makedirs(LOCAL_DATA_DIR,exist_ok=True)\n",
    "# Use prepared data handler from pytorch (torchvision)\n",
    "dataset = datasets.MNIST(LOCAL_DATA_DIR, train=True, download=True,\n",
    "                         transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-skiing",
   "metadata": {},
   "source": [
    "Here, MNIST is also a type `Dataset` (how? through class inheritance). All torch `Dataset` instance have tow useful and common functions: the length representations and data element access via index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( len(dataset)  )\n",
    "print( type(dataset[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-stand",
   "metadata": {},
   "source": [
    "That being said, how each data element is presented depends on a particular `Dataset` implementation. In case of MNIST, it is a tuple of length 2: **data** and **label**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTRY=0\n",
    "data, label = dataset[ENTRY]\n",
    "print('Type of data  :', type(data),  'shape', data.shape)\n",
    "print('Type of label :', type(label), 'value', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-nevada",
   "metadata": {},
   "source": [
    "MNIST is an image of a hand-written digit in 28x28 pixels, gray scale. Note that the data `shape` is `[1,28,28]`. This follows the convention in Pytorch for image data represented as $(Cannel,Height,Width)$, or in short $(C,H,W)$. Let's visualize using `matplotlib.pyplot.imshow`. This function can take $(H,W)$ of a gray scale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Draw data\n",
    "data = data.reshape(data.shape[1:])\n",
    "plt.imshow(data,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-bicycle",
   "metadata": {},
   "source": [
    "Let us define a function that can list images and labels in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset(dataset,num_image_per_class=10):\n",
    "    import numpy as np\n",
    "    num_class = 0\n",
    "    classes = []\n",
    "    if hasattr(dataset,'classes'):\n",
    "        classes=dataset.classes\n",
    "        num_class=len(classes)\n",
    "    else: #brute force\n",
    "        for data,label in dataset:\n",
    "            if label in classes: continue\n",
    "            classes.append(label)\n",
    "        num_class=len(classes)\n",
    "    \n",
    "    shape = dataset[0][0].shape\n",
    "    big_image = np.zeros(shape=[3,shape[1]*num_class,shape[2]*num_image_per_class],dtype=np.float32)\n",
    "    \n",
    "    finish_count_per_class=[0]*num_class\n",
    "    for data,label in dataset:\n",
    "        if finish_count_per_class[label] >= num_image_per_class: continue\n",
    "        img_ctr = finish_count_per_class[label]\n",
    "        big_image[:,shape[1]*label:shape[1]*(label+1),shape[2]*img_ctr:shape[2]*(img_ctr+1)]=data\n",
    "        finish_count_per_class[label] += 1\n",
    "        if np.sum(finish_count_per_class) == num_class*num_image_per_class: break\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig,ax=plt.subplots(figsize=(8,8),facecolor='w')\n",
    "    ax.tick_params(axis='both',which='both',bottom=False,top=False,left=False,right=False,labelleft=False,labelbottom=False)\n",
    "    plt.imshow(np.transpose(big_image,(1,2,0)))\n",
    "    for c in range(len(classes)):\n",
    "        plt.text(big_image.shape[1]+shape[1]*0.5,shape[2]*(c+0.6),str(classes[c]),fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-medicare",
   "metadata": {},
   "source": [
    "Visualize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-stopping",
   "metadata": {},
   "source": [
    "### Creating DataLoader\n",
    "\n",
    "Since the MNIST dataset is an iteratable one, we can create pytorch DataLoader!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "loader = torch.utils.data.DataLoader(dataset,\n",
    "                                     batch_size=20,\n",
    "                                     shuffle=True,\n",
    "                                     num_workers=1,\n",
    "                                     pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-supplement",
   "metadata": {},
   "source": [
    "**Review**: the first argument is you dataset, and it can be anything but requires two attributes: [`__len__`](https://docs.python.org/3/reference/datamodel.html#object.__len__) and [`__getitem__`](https://docs.python.org/3/reference/datamodel.html#object.__getitem__). In case you wonder, these attributes allow you to call `len(dataset)` and access dataset elements  by `dataset[X]` where `X` is an index integer.\n",
    "\n",
    "#### Details (ignore if wished): other constructor arguments\n",
    "The other constructor arguments used above are:\n",
    "* `batch_size` ... the same of the subset data to be provided at once\n",
    "* `shuffle` ... whether or not to randomize the choice of subset dataset (False will provide dataset\n",
    "* `num_workers` ... number of parallel data-reader processes to be run (for making data read faster using `multiprocessing` module)\n",
    "* `pin_memory` ... speed up data transfer to GPU by avoiding a necessity to copy data from pageable memory to page-locked (pinned) memory. Read [here](https://devblogs.nvidia.com/how-optimize-data-transfers-cuda-cc/) for more details. If you are not sure about the details, set to `True` when using GPU. \n",
    "\n",
    "### Data streaming with `DataLoader`\n",
    "So let's play with it! First of all, it has the concept of \"length\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('length of DataLoader:',len(loader))\n",
    "print('By the way, batch size * length =', 20 * len(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-sport",
   "metadata": {},
   "source": [
    "We know the data total statistics is 60,000 which coincides with the length of `DataLoader` instance and the batch size where the latter is the unit of batch data. **Yep, as you guessed**, `DataLoader` is iterable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an iterator for playin in this notebook\n",
    "from itertools import cycle\n",
    "iter = cycle(loader)\n",
    "\n",
    "for i in range(10):\n",
    "    batch = next(iter)    \n",
    "    print('Iteration',i)\n",
    "    print(batch[1]) # accessing the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-portuguese",
   "metadata": {},
   "source": [
    "... and this is how `data` looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of an image batch data',batch[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-sessions",
   "metadata": {},
   "source": [
    "... which is quite naturally 20 of 28x28 image\n",
    "\n",
    "\n",
    "## CIFAR10 \n",
    "\n",
    "`CIFAR10` is yet another public dataset of 32x32 pixels RGB photographs. It contains 10 classes like MNIST but it is much more complicated than a gray scale, hand-written digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "# Data file download directory\n",
    "LOCAL_DATA_DIR = './cifar10-data'\n",
    "# Create the dataset\n",
    "dataset = datasets.CIFAR10(LOCAL_DATA_DIR, train=True, download=True,\n",
    "                           transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "plot_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-lancaster",
   "metadata": {},
   "source": [
    "Nothing new in terms of how-to, but let's also create a `DataLoader` with `CIFAR10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset,batch_size=8,shuffle=True,num_workers=1,pin_memory=True)\n",
    "\n",
    "batch = next(cycle(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-struggle",
   "metadata": {},
   "source": [
    "Let's take a look at the `batch` data. Recall the shape of this image $(C,H,W)$ where `matplotlib.pyplot.imshow` takes the format $(H,W,C)$ just like how an ordinary photograph is presented. We use `torch.permute` function to swap the axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "photos,labels=batch\n",
    "for idx in range(len(photos)):\n",
    "    photo = photos[idx].permute(1,2,0)\n",
    "    label = labels[idx]\n",
    "    print(dataset.classes[label])\n",
    "    plt.imshow(photo)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "source_map": [
   14,
   19,
   25,
   33,
   42,
   45,
   48,
   51,
   56,
   59,
   67,
   70,
   101,
   104,
   106,
   111,
   118,
   131,
   134,
   137,
   146,
   149,
   151,
   159,
   168,
   171,
   175,
   178
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}